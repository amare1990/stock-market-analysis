{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f67b0107-aa30-4940-83c0-0348fb99e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'scripts')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cafaa25-db85-478f-82c2-94c87ce22f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/am/corpus/...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of stopwords: 179\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Add NLTK data path\n",
    "nltk.data.path.append('/home/am/corpus/')\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords', download_dir='/home/am/corpus/')\n",
    "\n",
    "# Verify stopwords\n",
    "try:\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    print(f\"Number of stopwords: {len(stop_words)}\")\n",
    "except LookupError as e:\n",
    "    print(f\"Error loading stopwords: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72794b98-d9a9-4458-a81e-9af71d319f45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLTK data path: ['/home/am/nltk_data', '/home/am/Documents/Software Development/10_Academy Training/week1/stock-market-analysis/venv-stock/nltk_data', '/home/am/Documents/Software Development/10_Academy Training/week1/stock-market-analysis/venv-stock/share/nltk_data', '/home/am/Documents/Software Development/10_Academy Training/week1/stock-market-analysis/venv-stock/lib/nltk_data', '/usr/share/nltk_data', '/usr/local/share/nltk_data', '/usr/lib/nltk_data', '/usr/local/lib/nltk_data', '/home/am/corpus/', '/home/am/corpus/']\n",
      "Number of stopwords: 179\n"
     ]
    }
   ],
   "source": [
    "from stock_text import clean_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "147f0ed1-a543-42cc-84dd-435a4cb115e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amare a phd studentaait hallas\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"Amare a            PhD          student@AAiT. Hallas!!!\"\n",
    "cleaned_text = clean_text(raw_text)\n",
    "print(cleaned_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c76347b8-d48b-44b1-9fb3-21349fbde77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load_data import load_data\n",
    "df = load_data(\"/home/am/Documents/Software Development/10_Academy Training/week1/Data/raw_analyst_ratings.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b9d651-dace-4ca2-ae07-34d183821b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from stock_text import perform_sentiment_analysis\n",
    "# # Perform sentiment analysis\n",
    "# df = perform_sentiment_analysis(df, column='headline')\n",
    "\n",
    "# # Display sentiment counts\n",
    "# print(df['sentiment_label'].value_counts())\n",
    "\n",
    "# # Save the modified DataFrame to a CSV file\n",
    "# df.to_csv('sentiment_analysis_output.csv', index=False)\n",
    "\n",
    "# # Display sentiment counts and save them to a text file\n",
    "# sentiment_counts = df['sentiment_label'].value_counts()\n",
    "\n",
    "# # Save sentiment counts to a text file\n",
    "# with open('sentiment_counts.txt', 'w') as f:\n",
    "#     f.write(str(sentiment_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff6de859-a2c5-4444-a689-e4dbff4c6467",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e86e1f35-4df9-4fcc-86de-8ac1e106fa8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 1: friday, stocks, highs, hit, week\n",
      "Topic 2: highs, hit, week, friday, stocks\n",
      "Topic 3: highs, hit, week, stocks, friday\n",
      "Topic 4: highs, hit, week, stocks, friday\n",
      "Topic 5: highs, hit, week, stocks, friday\n"
     ]
    }
   ],
   "source": [
    "from stock_text import extract_topics\n",
    "# Extract topics\n",
    "topics = extract_topics(df, column='headline', num_topics=5, num_keywords=10)\n",
    "\n",
    "# Display topics\n",
    "for topic, keywords in topics.items():\n",
    "    print(f\"{topic}: {', '.join(keywords)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1420ba5b-79e1-4461-bf42-71b33b6cc890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
